{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LZ78 Usage Tutorial: Sequential Probability Assignment (SPA)\n",
    "\n",
    "**Note**: please look at `Sequences.ipynb` first if you haven't already.\n",
    "\n",
    "## Prerequisites\n",
    "1. Follow the setup instructions in `tutorials/README.md`\n",
    "2. In the same Python environment as you used for that tutorial, run `pip install ipykernel`\n",
    "3. Use that Python environment as the kernel for this notebook.\n",
    "\n",
    "## Important Note\n",
    "Sometimes, Jupyter doesn't register that a cell containing code from the `lz78` library has started running, so it seems like the cell is waiting to run until it finishes.\n",
    "This can be annoying for operations that take a while to run, and **can be remedied by putting `stdout.flush()` at the beginning of the cell**.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lz78 import Sequence, LZ78SPA, spa_from_file, CharacterMap\n",
    "import os\n",
    "import requests\n",
    "from sys import stdout\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import pretty_print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LZ78 SPA\n",
    "\n",
    "The `LZ78SPA` class is the implementation of the family of sequential probability assignments discussed in [A Family of LZ78-based Universal Sequential Probability Assignments](https://arxiv.org/abs/2410.06589), for Dirichelt priors.\n",
    "\n",
    "Under this prior, the sequential probability assignment is an additive\n",
    "perturbation of the emprical distribution, conditioned on the LZ78 prefix\n",
    "of each symbol (i.e., the probability model is proportional to the\n",
    "number of times each node of the LZ78 tree has been visited, plus gamma).\n",
    "\n",
    "This SPA has the following capabilities:\n",
    "- training on one or more sequences,\n",
    "- log loss (\"perplexity\") computation for test sequences,\n",
    "- SPA computation (using the LZ78 context reached at the end of parsing\n",
    "    the last training block),\n",
    "- sequence generation.\n",
    "\n",
    "Note that the LZ78SPA does not perform compression; see `CompressorTutorial.ipynb` for how to perform LZ78 compression.\n",
    "\n",
    "## 1. Basic SPA Capabilities\n",
    "First, we go over the main capabilities of the LZ78 SPA, using the text of a Sherlock Holmes novel as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = requests.get(\"https://www.gutenberg.org/cache/epub/1661/pg1661.txt\").text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our own character map and filter the text based on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout.flush()\n",
    "charmap = CharacterMap(\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ. ,?\\n\\\"';:\\t-_\")\n",
    "filtered_text = charmap.filter_string(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us divide the text into a training and test split, each with 5 sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = len(filtered_text) // 10\n",
    "train_text = [filtered_text[i*SEQ_LEN:(i+1)*SEQ_LEN] for i in range(5)]\n",
    "test_text = [filtered_text[i*SEQ_LEN:(i+1)*SEQ_LEN] for i in range(5,10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 SPA Initialization\n",
    "To initialize an LZ78 SPA, you need to pass in the alphabet size of the sequences you plan to model with the SPA.\n",
    "\n",
    "You can also pass in these optional parameters:\n",
    "- `gamma` (default: `0.5`): this is the Dirichlet smoothing parameter of the SPA (see Section 2 for more details).\n",
    "\n",
    "    For alphabet size $A$, $\\frac{1}{A-1}$ can be a good heuristic for `gamma`, but is not guaranteed to work in all cases.\n",
    "- `compute_training_loss` (default: `True`): to save computation, you can choose to not compute the SPA log loss during training by setting `compute_training_loss=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spa = LZ78SPA(alphabet_size=charmap.alphabet_size(), gamma=1/(charmap.alphabet_size()-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 SPA Training\n",
    "\n",
    "You can train the LZ78 SPA via the `train_on_block` function, which takes in a `Sequence` as an input. This function returns the total log loss incurred when training on the input sequence.\n",
    "\n",
    "Optionally, call `spa.reset_state()` before `train_on_block` to return to the root in between input sequences (_note_: inference always starts at the root without having to call `reset_state`, but subsequent training resumes from the node where it left off)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout.flush()\n",
    "\n",
    "EPOCHS = 10\n",
    "for _ in tqdm(range(EPOCHS)):\n",
    "    for seq in train_text:\n",
    "        spa.reset_state()\n",
    "        spa.train_on_block(Sequence(seq, charmap=charmap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Freezing the Tree Structure**\n",
    "By passing in `freeze_tree=True` to `train_on_block`, you can update the counts without adding new leaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq in train_text:\n",
    "    spa.reset_state()\n",
    "    spa.train_on_block(Sequence(seq, charmap=charmap), freeze_tree=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pruning**\n",
    "The SPA can also be pruned via the `prune` instance method. This can be used to reduce memory usage, but generally reduces SPA accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment to prune the SPA\n",
    "# spa.prune(min_count=1) # this prunes any nodes that have not been visited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Basic SPA Inference\n",
    "\n",
    "Inference is performed using the `compute_test_loss` function, which takes in a `Sequence` as input.\n",
    "`compute_test_loss` returns a dictionary with the following fields:\n",
    "- `avg_log_loss`: log loss, averaged over symbols in the input sequence\n",
    "- `avg_perplexity`: $2^\\text{log loss}$, averaged over symbols in the input sequence\n",
    "- `log_losses` (only output if you pass in `output_per_symbol_losses=True` or `output_prob_dists=True`): log loss per symbol in the input sequence\n",
    "- `prob_dists` (only output if you pass in `output_prob_dists=True`): SPA for each symbol in the input sequence\n",
    "- `patch_info` (only output if you pass in `output_patch_info=True`): for each path taken from the root of the LZ78 tree to a leaf, the `patch_info` keeps track of what input symbols were involved in the traversal.\n",
    "    This output is a list of tuples of (traversal start index, traversal end index), where the end index is exclusive.\n",
    "\n",
    "    These \"patches\" may overlap if \"backshift parsing\" occurs (see below for a short description).\n",
    "\n",
    "#### Backshift Parsing:\n",
    "\n",
    "When we try to perform inference at the root or a leaf of the LZ78 tree, there is not enough information availble to produce a good probability estimate for the next symbol (leaves have not seen any symbols and thus have uniform SPA values, and the root does not take past context into consideration).\n",
    "So, instead of trying to perform inference at the root or leaf of the tree, we perform **backshift parsing** or **node relocation**:\n",
    "- Starting at some `backshift_ctx_len` indices before the current symbol, traverse the tree starting from the root until the current symbol\n",
    "- If we ever reach a leaf during this process, retry with a context of length `backshift_ctx_len - 1`. If that fails, try `backshift_ctx_len - 2`, etc.\n",
    "- Once we traverse to the curret symbol without reaching a leaf, we can continue inference as usual.\n",
    "\n",
    "Backshift parsing is enabled by default with `backshift_ctx_len = 5`.\n",
    "\n",
    "#### **Basic Inference Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout.flush()\n",
    "res = spa.compute_test_loss(Sequence(test_text[0], charmap=charmap))\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Outputting Per-Symbol Log Losses:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout.flush()\n",
    "res = spa.compute_test_loss(\n",
    "    Sequence(test_text[0][:100], charmap=charmap),\n",
    "    output_per_symbol_losses=True\n",
    ")\n",
    "log_losses = res['log_losses']\n",
    "\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.stem(log_losses, \"b\")\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Index\", fontdict={\"size\": 14})\n",
    "plt.ylabel(\"Log Loss\", fontdict={\"size\": 14})\n",
    "plt.xticks(size=12)\n",
    "plt.yticks(size=12)\n",
    "plt.title(\"Per-Symbol Log Loss of LZ78 SPA\", fontdict={\"size\": 18})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Outputting SPAs for each index of the test sequence:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout.flush()\n",
    "res = spa.compute_test_loss(\n",
    "    Sequence(test_text[0][:100], charmap=charmap),\n",
    "    output_prob_dists=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = 15\n",
    "prob_dist = res['prob_dists'][IDX]\n",
    "\n",
    "plt.figure(figsize=(15,3))\n",
    "plt.stem(prob_dist, \"r\")\n",
    "plt.grid(True)\n",
    "x = list(range(len(prob_dist)))\n",
    "plt.xticks(ticks=x, labels=charmap.decode(list(x)), size=12)\n",
    "plt.yticks(size=12)\n",
    "plt.ylabel(\"SPA Value\", fontdict={\"size\": 14})\n",
    "plt.title(f\"Probability of each symbol at index {IDX}\\n(actual next symbol: \\\"{test_text[0][IDX]}\\\", \\\n",
    "log loss: {round(res['log_losses'][IDX], 4)})\", fontdict={\"size\": 18})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Outputting root-to-leaf traversal information:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout.flush()\n",
    "res = spa.compute_test_loss(\n",
    "    Sequence(test_text[0][:25], charmap=charmap),\n",
    "    output_patch_info=True\n",
    ")\n",
    "for i, info in enumerate(res['patch_info']):\n",
    "    print(f\"Traversal {i} uses indices {info[0]} through {info[1] - 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 SPA Inference Features: Context and Parallelism\n",
    "\n",
    "LZ78 SPA Inference also supports passing in a **context**, which is a `Sequence` that is assumed to occur directly before the input on which the test log loss is being computed.\n",
    "This context is used for backshift parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout.flush()\n",
    "res = spa.compute_test_loss(\n",
    "    input=Sequence(test_text[0][5:], charmap=charmap),\n",
    "    context=Sequence(test_text[0][:5], charmap=charmap)\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Parallelism**\n",
    "Inference on multiple test sequences can be performed in parallel using the function `compute_test_loss_parallel`, which takes in a list of input sequences and returns a list of output dictionaries.\n",
    "\n",
    "A context can also be provided for parallel inference; in that case, a context must be provided for each input sequence: the `context` argument is a list of the same legth as the `input` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [Sequence(seq[5:], charmap=charmap) for seq in test_text]\n",
    "contexts = [Sequence(seq[:5], charmap=charmap) for seq in test_text]\n",
    "\n",
    "stdout.flush()\n",
    "res = spa.compute_test_loss_parallel(\n",
    "    inputs, contexts, num_threads=8\n",
    ")\n",
    "print(\"Log losses: \", [r['avg_log_loss'] for r in res])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Generation\n",
    "\n",
    "The `generate_data` method generates a sequence from the SPA, using temperature and top-k sampling.\n",
    "\n",
    "It takes in as arguments:\n",
    "- **len**: number of symbols to generate\n",
    "- **seed_data**: you can specify that the sequence of generated data\n",
    "    be the continuation of the specified sequence.\n",
    "- **temperature**: a measure of how \"random\" the generated sequence is. A\n",
    "    temperature of 0 deterministically generates the most likely\n",
    "    symbols, and a temperature of 1 samples directly from the SPA.\n",
    "    Temperature values around 0.1 or 0.2 function well.\n",
    "- **top_k**: forces the generated symbols to be of the top_k most likely\n",
    "    symbols at each timestep.\n",
    "\n",
    "Returns a tuple of the generated sequence and that sequence's log loss,\n",
    "or perplexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_DATA = \"This \"\n",
    "\n",
    "stdout.flush()\n",
    "(generated, log_loss) = spa.generate_data(\n",
    "    len=1000, seed_data=Sequence(SEED_DATA, charmap=charmap),\n",
    "    temperature=0.1, top_k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(SEED_DATA + generated.get_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SPA Configuration\n",
    "\n",
    "For inference and generation, there are some hyperparameters that can be tuned for SPA accuracy.\n",
    "\n",
    "### 2.1 Configuration settings:\n",
    "- `gamma`: this is the \"Dirichlet smoothing parameter,\" which perturbs the probability model at each node of the LZ78 tree from empirical distribution of symbols seen at that node.\n",
    "\n",
    "    A higher value of `gamma` means that the probability models at each node tend more towards a uniform distribution. $\\frac{1}{A-1}$, where $A$ is the size of the alphabet, is a good heuristic but might not work well in all cases.\n",
    "\n",
    "    **Possible values:** floats > 0\n",
    "\n",
    "    **Default**: `0.5`\n",
    "\n",
    "- `adaptive_gamma`: whether to scale `gamma` to be smaller for deeper nodes, or for nodes that have seen fewer symbols.\n",
    "\n",
    "    **Possible values:**\n",
    "    - `\"disabled\"`\n",
    "    - `\"inverse\"`: smaller `gamma` for deeper nodes. The motivation for this is that deeper nodes have a longer context, so their empirical distributions can be \"trusted\" more.\n",
    "    - `\"count\"`: smaller `gamma` for nodes that have seen fewer symbols. This protects against Dirichlet regulatization that is too aggressive for nodes that have seen fewer symbols but not strong enough for nodes that have been traversed many times.\n",
    "\n",
    "    **Default:** `\"disabled\"`\n",
    "\n",
    "- `temp`: temperature parameter, where temperature is applied as $\\text{SPA}(a) \\gets \\frac{\\text{exp}\\left\\{\\log\\left(\\text{SPA}(a)\\right)/T\\right\\}}{\\sum_{b < A} \\text{exp}\\left\\{\\log\\left(\\text{SPA}(b)\\right)/T\\right\\}}$ (where $T$ is the temperature parameter).\n",
    "\n",
    "    **Possible values:** floats >= 0\n",
    "\n",
    "    **Default:** `1` (same as no temperature applied)\n",
    "\n",
    "- `lb`: lower bound on the probability values from the SPA (if any value is too close to zero, it is set to this value).\n",
    "\n",
    "    **Possible values:** floats >= 0\n",
    "\n",
    "    **Default:** `0.0001`\n",
    "\n",
    "- `lb_or_temp_first`: whether to apply lower bound or temperature first.\n",
    "\n",
    "    **Possible values:** `\"lb_first\"`, `\"temp_first\"`, `\"disabled\"`\n",
    "\n",
    "    **Default:** `\"lb_first\"`\n",
    "\n",
    "- `backshift_parsing`: boolean for whether to enable backshift parsing. In backshift parsing, whenever we reach a leaf, we return to the root of the tree and use the most recently-seen symbols to traverse the tree, hopefully arriving at a location with a more accurate SPA. See Section 1.3 for a more detailed description of the procedure.\n",
    "\n",
    "    **Possible values:** booleans\n",
    "\n",
    "    **Default:** `True`\n",
    "\n",
    "- `backshift_ctx_len`: length of the context of recetly-seen symbols to use for backshift parsing.\n",
    "\n",
    "    **Possible values:** integers >= 1\n",
    "\n",
    "    **Default:** `5`\n",
    "\n",
    "- `backshift_break_at_phrase`: whether to continue backshift parsing at a certain shift after a return to the root, or to move on to the next shift.\n",
    "\n",
    "    **Possible values:** booleans\n",
    "\n",
    "    **Default:** `True`\n",
    "\n",
    "- `ensemble_type`: If **ensemble inference** is enabled, then the SPA is evaluated at several nodes of different depths (corresponding to contexts of different lengths). This typically trades off inference accuracy with inference speed.\n",
    "\n",
    "    **Possible values:**\n",
    "    - `\"disabled\"`\n",
    "    - `\"average\"`: average the ensemble SPAs\n",
    "    - `\"entropy\"`: weight the average based on the entropy of each SPA\n",
    "    - `\"depth\"` to weight the average based on the node depths\n",
    "\n",
    "    **Default:** `\"disabled\"`\n",
    "\n",
    "- `ensemble_n`: maximum number of nodes to use for the ensemble.\n",
    "\n",
    "    **Possible values:** integers >= 1\n",
    "\n",
    "    **Default:** `1`\n",
    "\n",
    "Much of these options come from [chwoong/lz](https://github.com/chwoong/lz/tree/master).\n",
    "\n",
    "### 2.2 Printing out current inference and generation config\n",
    "Note that the lower bound and temperature are not part of the generation config, as temperature and topk is already passed into the `generate_data` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spa.get_inference_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spa.get_generation_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Setting inference and generation config\n",
    "\n",
    "The following set of parameters may work well for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spa.set_inference_config(\n",
    "    lb=1e-5,\n",
    "    temp=1,\n",
    "    lb_or_temp_first=\"lb_first\",\n",
    "    ensemble_type=\"depth\",\n",
    "    ensemble_n=6,\n",
    "    backshift_parsing=True,\n",
    "    backshift_ctx_len=10,\n",
    "    backshift_break_at_phrase=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spa.set_generation_config(\n",
    "    ensemble_type=\"depth\",\n",
    "    ensemble_n=5,\n",
    "    backshift_parsing=True,\n",
    "    backshift_ctx_len=10,\n",
    "    backshift_break_at_phrase=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Testing out inference with these parameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [Sequence(seq[10:], charmap=charmap) for seq in test_text]\n",
    "contexts = [Sequence(seq[:10], charmap=charmap) for seq in test_text]\n",
    "\n",
    "stdout.flush()\n",
    "res = spa.compute_test_loss_parallel(\n",
    "    inputs, contexts, num_threads=8\n",
    ")\n",
    "print(\"Log losses: \", [r['avg_log_loss'] for r in res])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Testing out generation with these parameters:**\n",
    "\n",
    "Tuning hyperparameters typically results in less of a qualitative improvement for generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_DATA = \"This \"\n",
    "\n",
    "stdout.flush()\n",
    "(generated, log_loss) = spa.generate_data(\n",
    "    len=1000, seed_data=Sequence(SEED_DATA, charmap=charmap),\n",
    "    temperature=0.1, top_k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(SEED_DATA + generated.get_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Saving the SPA to Disk\n",
    "\n",
    "The SPA can be saved to a file using the `to_file` instance method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"test_data\", exist_ok=True)\n",
    "stdout.flush()\n",
    "spa.to_file(\"test_data/SPAoutput.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be loaded from a file via the `spa_from_file` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout.flush()\n",
    "loaded_spa = spa_from_file(\"test_data/SPAoutput.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout.flush()\n",
    "res1 = loaded_spa.compute_test_loss(Sequence(test_text[0], charmap=charmap))\n",
    "res2 = spa.compute_test_loss(Sequence(test_text[0], charmap=charmap))\n",
    "assert res1 == res2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Debugging Features: Leaf Depths\n",
    "By passing in `return_leaf_depths=True` to `train_on_block`, the function will return a list with the depth of each new leaf added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout.flush()\n",
    "spa = LZ78SPA(alphabet_size=charmap.alphabet_size(), gamma=1/(charmap.alphabet_size()-1))\n",
    "res = spa.train_on_block(Sequence(\"\".join(train_text), charmap=charmap), return_leaf_depths=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_depths = res['leaf_depths']\n",
    "\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.scatter(range(len(leaf_depths)), leaf_depths, c=\"b\")\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Node Number\", fontdict={\"size\": 14})\n",
    "plt.ylabel(\"Depth\", fontdict={\"size\": 14})\n",
    "plt.xticks(size=12)\n",
    "plt.yticks(size=12)\n",
    "plt.title(\"Depths of Leaves Added to LZ78 SPA\", fontdict={\"size\": 18})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity check**: if the tree is frozen, no new leaves are added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = spa.train_on_block(Sequence(\"\".join(train_text), charmap=charmap),\n",
    "                         return_leaf_depths=True, freeze_tree=True)\n",
    "assert len(res[\"leaf_depths\"]) == 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lz_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
