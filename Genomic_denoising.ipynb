{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoiser for Genomic Data\n",
    "### Setup\n",
    "Remember to do `cd crates/python/ && maturin develop && cd ../..` from the `lz78_rust` directory after making any changes to the Rust or the Python interface!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sys import stdout\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.signal as signal\n",
    "from scipy.linalg import toeplitz\n",
    "import dill as pickle\n",
    "from lz78 import Sequence, LZ78Encoder, CharacterMap, BlockLZ78Encoder, LZ78SPA\n",
    "from lz78 import encoded_sequence_from_bytes, spa_from_bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1202220303\n"
     ]
    }
   ],
   "source": [
    "# Load a section of DNA sequence in /test_data/DNA_4M.txt\n",
    "with open('test_data/DNA_100K_int.txt', 'r') as f:\n",
    "    DNA_data = f.read().translate({ord('\\n'): None})\n",
    "print(DNA_data[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout.flush()\n",
    "spa = LZ78SPA(4, gamma=1) # try 1/2 or 2 may work better for genomic data\n",
    "charmap_str = \"0123\"+DNA_data  ## IMPORTANT: do specify the sequence of the alphabet you want to train on. I'll make this more robust in the next update.\n",
    "char_map =  CharacterMap(charmap_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout.flush() ## add for any long process\n",
    "sequence = Sequence(DNA_data, charmap = char_map)\n",
    "train_loss = spa.train_on_block(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pi=np.array([[0.7, 0.1, 0.1, 0.1],\n",
    "       [0.1, 0.7, 0.1, 0.1],\n",
    "       [0.1, 0.1, 0.7, 0.1],\n",
    "       [0.1, 0.1, 0.1, 0.7]])\n",
    "alphabet = ['A', 'G', 'T', 'C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3425742574257426,\n",
       " 0.2524752475247525,\n",
       " 0.21485148514851485,\n",
       " 0.1900990099009901]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WL = 5 ## window length\n",
    "LAH = 1 ## look ahead\n",
    "test_data =  \"032101233212323220203030232010212120200101030102022111321212112230033203021030\"\n",
    "test_data = char_map.encode(test_data)\n",
    "pdf_traverse = spa.traverse_and_get_prob(test_data[:WL])\n",
    "pdf_traverse ## the fifth symbol is n for when DNA data is undefined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.36893203883495146,\n",
       " 0.30097087378640774,\n",
       " 0.2961165048543689,\n",
       " 0.03398058252427184]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_lookahead = spa.traverse_and_get_prob_with_lookahead(input= test_data[:WL], lookahead=test_data[WL:WL+LAH]) \n",
    "pdf_lookahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def universal_denoiser_naive(signal_to_filter, spa_tree, char_map, window_len,pi_matrix, x_alphabet):\n",
    "    sequence_l = len(signal_to_filter)\n",
    "    \n",
    "    Zt_index = signal_to_filter[window_len:sequence_l]\n",
    "    print(Zt_index[:10  ])\n",
    "    filtered_signal = []\n",
    "    for il in range(sequence_l-window_len):\n",
    "        prob = spa_tree.traverse_and_get_prob(signal_to_filter[il:il+window_len])\n",
    "        PX_t_Z_tm1_ele=np.matmul(np.linalg.inv(np.transpose(pi_matrix)),prob)\n",
    "        alphabet_ind = Zt_index[il]\n",
    "        num = pi_matrix[:,alphabet_ind] * PX_t_Z_tm1_ele\n",
    "        den = prob[alphabet_ind]\n",
    "        pxt = num/den\n",
    "        pxt = pxt/np.sum(pxt)\n",
    "        xt_hat = np.dot(pxt,x_alphabet)\n",
    "        filtered_signal.append(xt_hat)\n",
    "    \n",
    "    return filtered_signal\n",
    "\n",
    "def get_prob_from_MC(Dd, seed_str, spa_tree, char_map,num_exper):\n",
    "    generated_seq = []\n",
    "    for i_mc in range(num_exper):\n",
    "        output, loss = spa_tree.generate_data(Dd, seed_data = seed_str,temperature =1, min_context= 3)\n",
    "        generated_seq.append(output)\n",
    "    # count the number of times of last element in the generated sequence\n",
    "    prob = np.zeros(3)\n",
    "    for i in range(num_exper):\n",
    "        # charmap the generated sequence\n",
    "        generated_ind = char_map.str_to_symbol_list(generated_seq[i][-1])\n",
    "        #print(generated_ind)    \n",
    "        prob[generated_ind] += 1\n",
    "    prob = prob/num_exper\n",
    "    return prob\n",
    "\n",
    "def universal_denoiser_delay_mc(Delay,signal_to_filter_mc, spa_tree, char_map, \n",
    "                                window_len,pi_matrix, x_alphabet, num_exp):\n",
    "    sequence_len = len(signal_to_filter_mc) \n",
    "    Zt_index = char_map.str_to_symbol_list(signal_to_filter_mc[window_len:sequence_len])\n",
    "    filtered_signal_delay_mc = []\n",
    "    for idmc in range(sequence_len-window_len):\n",
    "        Zt_seed_str = signal_to_filter_mc[idmc:window_len+idmc-Delay]\n",
    "        prob_mc = get_prob_from_MC(Delay, Zt_seed_str, spa_tree, num_exp)\n",
    "        \n",
    "        PX_t_Z_tm1_mc = np.matmul(np.linalg.inv(np.transpose(pi_matrix)),prob_mc)\n",
    "        alphabet_ind = Zt_index[idmc]\n",
    "        #print(alphabet_ind)\n",
    "        num = pi_matrix[:,alphabet_ind] * PX_t_Z_tm1_mc\n",
    "        den = prob_mc[alphabet_ind]\n",
    "        pxt = num/den\n",
    "        pxt = pxt/np.sum(pxt)\n",
    "        xt_hat_mc = np.dot(pxt,x_alphabet)\n",
    "        #print(xt_hat_mc)\n",
    "        filtered_signal_delay_mc.append(xt_hat_mc)\n",
    "    \n",
    "    #print(filtered_signal_delay_mc)\n",
    "\n",
    "    return filtered_signal_delay_mc\n",
    "def universal_denoiser_lookahead(Lookahead,signal_to_filter_la, spa_tree, char_map: CharacterMap, \n",
    "                                window_len,pi_matrix, x_alphabet):\n",
    "\n",
    "    sequence_len = len(signal_to_filter_la) \n",
    "    Zt_index =signal_to_filter_la[window_len:sequence_len]\n",
    "    \n",
    "    filtered_signal_lookahead = []\n",
    "    #signal_to_filter_la = np.array(signal_to_filter_la)\n",
    "    for ila in range(sequence_len-window_len):\n",
    "        Zt_seed_str = signal_to_filter_la[ila:window_len+ila]\n",
    "        Zt_lookahead_str = signal_to_filter_la[ila+window_len:ila+window_len+Lookahead]\n",
    "\n",
    "        Zt_seed_vec = Zt_seed_str\n",
    "        Zt_lookahead_vec = Zt_lookahead_str\n",
    "        prob_la = spa_tree.traverse_and_get_prob_with_lookahead(Zt_seed_vec, Zt_lookahead_vec)\n",
    "        \n",
    "        PX_t_Z_tm1_la = np.matmul(np.linalg.inv(np.transpose(pi_matrix)),prob_la)\n",
    "        alphabet_ind = Zt_index[ila]\n",
    "        num = pi_matrix[:,alphabet_ind] * PX_t_Z_tm1_la\n",
    "        den = prob_la[alphabet_ind]\n",
    "        if den == 0:\n",
    "            #break and have average of x_alphabet\n",
    "            xt_hat_la = np.mean(x_alphabet)\n",
    "        else:\n",
    "            pxt = num/den\n",
    "            pxt = pxt/np.sum(pxt)\n",
    "            xt_hat_la = np.dot(pxt,x_alphabet)\n",
    "        filtered_signal_lookahead.append(xt_hat_la)\n",
    "    \n",
    "    return filtered_signal_lookahead    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout.flush()\n",
    "LAH =1# lookahead\n",
    "WL = 5 # window length\n",
    "#load noisy sequence\n",
    "with open('test_data/DNA_100K_int_noisy.txt', 'r') as f:\n",
    "    Zt_str = f.read()\n",
    "alphabet_Xt = [0,1,2,3] # A,G,T,C\n",
    "Zt_to_filter = char_map.encode(Zt_str[:100]) ## this converts the string to a vec\n",
    "#Xt_hat = universal_denoiser_naive(Zt_to_filter, spa, char_map,WL, pi_matrix_true, alphabet_Xt)\n",
    "Xt_hat = universal_denoiser_lookahead(LAH,Zt_to_filter, spa, char_map,WL, Pi, alphabet_Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load X_clean\n",
    "with open('test_data/DNA_100K_int.txt', 'r') as f:\n",
    "    Xt = f.read()\n",
    "# convert string to integer\n",
    "Xt = char_map.encode(Xt[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9765414609974967"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_clean = Xt[WL:]\n",
    "# calculate the mean squared error on not-nan values\n",
    "MSE_loss = 0 \n",
    "k = 0\n",
    "for i in range(len(Xt_hat)):\n",
    "    if not np.isnan(Xt_hat[i]):\n",
    "        loss_ind = (Xt_hat[i] - X_clean[i])**2\n",
    "        MSE_loss += loss_ind\n",
    "\n",
    "MSE_loss = MSE_loss/len(Xt_hat)\n",
    "\n",
    "MSE_loss\n",
    "# I honestly don't know what loss function you guys use so you might need to write your own argmin function adapting to your loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
