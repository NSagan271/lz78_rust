{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lz_embed.classical import BasicNGramSpectrum, AlphabetInfo, NGramSpectrumEmbedding\n",
    "import matplotlib.pyplot as plt\n",
    "import mteb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicNGramSpectrum(\n",
    "    alpha_info=AlphabetInfo(valid_character_string=\"abcdefghijklmnopqrstuvwxyz\"),\n",
    "    n=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,3))\n",
    "plt.plot(model.encode([\n",
    "    \"Hello world hello world I am a hello of the world hello hello world world wow wow hello hello\"\n",
    "])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,3))\n",
    "plt.plot(model.encode([\n",
    "    \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\"\n",
    "])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try on some of the MTEB tasks\n",
    "\n",
    "This does surprisingly well for a 2-gram model (3-gram is slow and the embeddings are prohibitively large). It does pretty poorly for some tasks, but this is a surprising result for something that is completely model-free.\n",
    "\n",
    "**Next steps**:\n",
    "- Do PCA to reduce the dimension. Does it help or hurt accuracy?\n",
    "- Try this but for token counts. This must have been tried before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NGramSpectrumEmbedding(\n",
    "    alpha_info=AlphabetInfo(valid_character_string=\"abcdefghijklmnopqrstuvwxyz\"),\n",
    "    n=2, lowercase=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = mteb.get_tasks(tasks=[\"DBpediaClassification\"])\n",
    "evaluation = mteb.MTEB(tasks=tasks)\n",
    "\n",
    "results = evaluation.run(\n",
    "    model, output_folder=f\"results/test\",\n",
    "    show_progress_bar=True,\n",
    "    overwrite_results=True\n",
    ")\n",
    "print(\"SCORE: \", results[0].scores[\"test\"][0][\"main_score\"] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = mteb.get_tasks(tasks=[\"AILAStatutes\"])\n",
    "evaluation = mteb.MTEB(tasks=tasks)\n",
    "\n",
    "results = evaluation.run(\n",
    "    model, output_folder=f\"results/test\",\n",
    "    show_progress_bar=True,\n",
    "    overwrite_results=True\n",
    ")\n",
    "print(\"SCORE: \", results[0].scores[\"test\"][0][\"main_score\"] * 100)\n",
    "print(\"M2V_base_output (potion but worse): 12.725\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = mteb.get_tasks(tasks=[\"TweetTopicSingleClassification\"])\n",
    "evaluation = mteb.MTEB(tasks=tasks)\n",
    "\n",
    "results = evaluation.run(\n",
    "    model, output_folder=f\"results/test\",\n",
    "    show_progress_bar=True,\n",
    "    overwrite_results=True\n",
    ")\n",
    "print(\"SCORE: \", results[0].scores[\"test_2021\"][0][\"main_score\"] * 100)\n",
    "print(\"M2V_base_output (potion but worse): 46.21\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = mteb.get_tasks(tasks=[\"PoemSentimentClassification\"])\n",
    "evaluation = mteb.MTEB(tasks=tasks)\n",
    "\n",
    "results = evaluation.run(\n",
    "    model, output_folder=f\"results/test\",\n",
    "    show_progress_bar=True,\n",
    "    overwrite_results=True\n",
    ")\n",
    "print(\"SCORE: \", results[0].scores[\"test\"][0][\"main_score\"] * 100)\n",
    "print(\"M2V_base_output (potion but worse): 35.7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = mteb.get_tasks(tasks=[\"ArXivHierarchicalClusteringP2P\"])\n",
    "evaluation = mteb.MTEB(tasks=tasks)\n",
    "\n",
    "results = evaluation.run(\n",
    "    model, output_folder=f\"results/test\",\n",
    "    show_progress_bar=True,\n",
    "    overwrite_results=True\n",
    ")\n",
    "print(\"SCORE: \", results[0].scores[\"test\"][0][\"main_score\"] * 100)\n",
    "print(\"M2V_base_output (potion but worse): 51.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = mteb.get_tasks(tasks=[\"ArXivHierarchicalClusteringS2S\"])\n",
    "evaluation = mteb.MTEB(tasks=tasks)\n",
    "\n",
    "results = evaluation.run(\n",
    "    model, output_folder=f\"results/test\",\n",
    "    show_progress_bar=True,\n",
    "    overwrite_results=True\n",
    ")\n",
    "print(\"SCORE: \", results[0].scores[\"test\"][0][\"main_score\"] * 100)\n",
    "print(\"M2V_base_output (potion but worse): 44.15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = mteb.get_tasks(tasks=[\"ArguAna\"])\n",
    "evaluation = mteb.MTEB(tasks=tasks)\n",
    "\n",
    "results = evaluation.run(\n",
    "    model, output_folder=f\"results/test\",\n",
    "    show_progress_bar=True,\n",
    "    overwrite_results=True\n",
    ")\n",
    "print(\"SCORE: \", results[0].scores[\"test\"][0][\"main_score\"] * 100)\n",
    "print(\"M2V_base_output (potion but worse): 29.18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = mteb.get_tasks(tasks=[\"WikiCitiesClustering\"])\n",
    "evaluation = mteb.MTEB(tasks=tasks)\n",
    "\n",
    "results = evaluation.run(\n",
    "    model, output_folder=f\"results/test\",\n",
    "    show_progress_bar=True,\n",
    "    overwrite_results=True\n",
    ")\n",
    "print(\"SCORE: \", results[0].scores[\"test\"][0][\"main_score\"] * 100)\n",
    "print(\"M2V_base_output (potion but worse): 57.81\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
