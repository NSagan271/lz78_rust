{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 18:40:58.489644: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-24 18:40:58.506043: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742866858.524876 1449353 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742866858.530710 1449353 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-24 18:40:58.550457: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from lz78 import Sequence, LZ78SPA\n",
    "from lz_python.lz import LZModel\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from sys import stdout\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PG19DataLoader:\n",
    "    def __init__(self, data_type: str, start_index: int = 0, batch_size: int = 1, normalize: str = 'none'):\n",
    "        self.data = tfds.load('pg19', split=data_type, shuffle_files=False)\n",
    "        self.dataset = (self.data\n",
    "                        .skip(start_index)\n",
    "                        .batch(batch_size)\n",
    "                        .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "        print(data_type, \": \", len(self.dataset))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.dataset:\n",
    "            text_bytes = np.frombuffer(batch['book_text'].numpy()[0], dtype=np.uint8)\n",
    "            text_bytes = text_bytes.tolist()\n",
    "            yield text_bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigObject:\n",
    "    def __init__(self, config_dict):\n",
    "        self.__dict__.update(config_dict)\n",
    "\n",
    "config = ConfigObject({\n",
    "    \"top_k\": 256,\n",
    "    \"method\": \"Depth-Guided\", # ensemble\n",
    "    \"ensemble_max_num\": 6,\n",
    "    \"min_depth\": 10,\n",
    "    \"vocab_size\": 256,\n",
    "    \"adaptive_gamma\": \"none\",\n",
    "    \"gamma\": 1/256,\n",
    "    \"lower_bound\": 1e-5,\n",
    "    \"temp\": 1,\n",
    "    \"ensemble_type\": \"depth\",\n",
    "    \"lb_or_temp\": \"lb_first\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_lz = LZModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rust_lz = LZ78SPA(alphabet_size=256, gamma=1/256, compute_training_loss=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  28602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building LZ tree:   0%|          | 0/28602 [00:00<?, ?it/s]2025-03-24 18:41:28.530776: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:376] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n",
      "Building LZ tree:   0%|          | 99/28602 [00:04<23:27, 20.25it/s] \n"
     ]
    }
   ],
   "source": [
    "N_TRAIN = 100\n",
    "\n",
    "stdout.flush()\n",
    "train_dataloader = PG19DataLoader(\"train\")\n",
    "rust_lz.reset_state()\n",
    "for trn_iter, batch in enumerate(tqdm(train_dataloader, desc=\"Building LZ tree\"), start=1):\n",
    "    # build LZ model only 1 epoch\n",
    "    stdout.flush()\n",
    "    rust_lz.train_on_block(Sequence(batch, alphabet_size=256))\n",
    "    rust_lz.reset_state()\n",
    "\n",
    "    if trn_iter >= N_TRAIN:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  28602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building LZ tree:   0%|          | 99/28602 [00:17<1:23:18,  5.70it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = PG19DataLoader(\"train\")\n",
    "for trn_iter, batch in enumerate(tqdm(train_dataloader, desc=\"Building LZ tree\"), start=1):\n",
    "    # build LZ model only 1 epoch\n",
    "    py_lz.build_tree(batch)\n",
    "\n",
    "    if trn_iter >= N_TRAIN:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rust_lz.set_inference_config(\n",
    "    lb=1e-5,\n",
    "    temp=1,\n",
    "    lb_or_temp_first=\"lb_first\",\n",
    "    ensemble_type=\"depth\",\n",
    "    ensemble_n=6,\n",
    "    adaptive_gamma=\"disabled\",\n",
    "    backshift_parsing=True,\n",
    "    backshift_ctx_len=10,\n",
    "    backshift_break_at_phrase=True\n",
    ")\n",
    "\n",
    "py_lz.config = ConfigObject({\n",
    "    \"top_k\": 256,\n",
    "    \"method\": \"Depth-Guided\", # ensemble\n",
    "    \"ensemble_max_num\": 6,\n",
    "    \"min_depth\": 10,\n",
    "    \"vocab_size\": 256,\n",
    "    \"adaptive_gamma\": \"none\",\n",
    "    \"gamma\": 1/256,\n",
    "    \"lower_bound\": 1e-5,\n",
    "    \"temp\": 1,\n",
    "    \"ensemble_type\": \"depth\",\n",
    "    \"lb_or_temp\": \"lb_first\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation :  50\n"
     ]
    }
   ],
   "source": [
    "val_dataloader = PG19DataLoader(\"validation\")\n",
    "test_seq = next(iter(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seqs = []\n",
    "for i in range(0, len(test_seq)-1023, 512):\n",
    "    test_seqs.append(test_seq[i:i+1024])\n",
    "\n",
    "test_seqs = test_seqs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = rust_lz.compute_test_loss_parallel(\n",
    "    [Sequence(seq, alphabet_size=256) for seq in test_seqs], output_patch_info=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout.flush()\n",
    "\n",
    "inputs = [Sequence(seq[512:],alphabet_size=256) for seq in test_seqs]\n",
    "ctxs = [Sequence(seq[:512],alphabet_size=256) for seq in test_seqs]\n",
    "\n",
    "res = rust_lz.compute_test_loss_parallel(\n",
    "    inputs, ctxs, num_threads=32, output_prob_dists=False, output_per_symbol_losses=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.09570746 2.02709416 1.92888051 2.24193296 1.94838384 2.246818\n",
      " 2.5534734  1.92000791 2.23535322 2.14238168]\n"
     ]
    }
   ],
   "source": [
    "print(np.array([x[\"avg_log_loss\"] for x in res]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.09570746 2.02709416 1.92888051 2.24193296 1.94838384 2.246818\n",
      " 2.5534734  1.92000791 2.23535322 2.14238168]\n"
     ]
    }
   ],
   "source": [
    "py_lz_losses = []\n",
    "for seq in test_seqs:\n",
    "    depths, btb, _ = py_lz.get_depth_and_perplexity(seq)\n",
    "    py_lz_losses.append(float(np.mean(btb)))\n",
    "print(np.array(py_lz_losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Full Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss = 0\n",
    "n_seqs = 0\n",
    "val_dataloader = PG19DataLoader(\"validation\")\n",
    "for seq in tqdm(val_dataloader):\n",
    "    stdout.flush()\n",
    "    test_seqs = []\n",
    "    for i in range(0, len(seq)-1023, 512):\n",
    "        test_seqs.append(seq[i:i+1024])\n",
    "\n",
    "    rust_lz.reset_state()\n",
    "\n",
    "    inputs = [Sequence(seq[64:],alphabet_size=256) for seq in test_seqs]\n",
    "    ctxs = [Sequence(seq[:64],alphabet_size=256) for seq in test_seqs]\n",
    "\n",
    "    res = rust_lz.compute_test_loss_parallel(\n",
    "        inputs, ctxs, num_threads=32, output_prob_dists=False, output_per_symbol_losses=False\n",
    "    )\n",
    "\n",
    "    log_loss += np.sum(np.array([x[\"avg_log_loss\"] for x in res]))\n",
    "    n_seqs += len(test_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Val loss: {float(log_loss / n_seqs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return Patch Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = PG19DataLoader(\"validation\")\n",
    "test_seq = next(iter(val_dataloader))[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = rust_lz.compute_test_loss( # also works for the parallel version!\n",
    "    Sequence(test_seq, alphabet_size=256), output_prob_dists=False, output_per_symbol_losses=True, output_patch_info=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This looks reasonable; should maybe debug more\n",
    "for info in res['patch_info']:\n",
    "    print(f\"{info[0]} through {info[1] - 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.stem(np.array(res['log_losses']))\n",
    "plt.title(\"Log Loss per Symbol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lz_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
