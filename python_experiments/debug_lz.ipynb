{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 11:23:53.048247: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-12 11:23:53.063918: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741803833.082431 1459657 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741803833.088064 1459657 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-12 11:23:53.108615: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from lz78 import Sequence, LZ78SPA\n",
    "from lz_python.lz import LZModel\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from sys import stdout\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PG19DataLoader:\n",
    "    def __init__(self, data_type: str, start_index: int = 0, batch_size: int = 1, normalize: str = 'none'):\n",
    "        self.data = tfds.load('pg19', split=data_type, shuffle_files=False)\n",
    "        self.dataset = (self.data\n",
    "                        .skip(start_index)\n",
    "                        .batch(batch_size)\n",
    "                        .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "        print(data_type, \": \", len(self.dataset))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.dataset:\n",
    "            text_bytes = np.frombuffer(batch['book_text'].numpy()[0], dtype=np.uint8)\n",
    "            text_bytes = text_bytes.tolist()\n",
    "            yield text_bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigObject:\n",
    "    def __init__(self, config_dict):\n",
    "        self.__dict__.update(config_dict)\n",
    "\n",
    "config = ConfigObject({\n",
    "    \"top_k\": 256,\n",
    "    \"method\": \"Depth-Guided\", # ensemble\n",
    "    \"ensemble_max_num\": 6,\n",
    "    \"min_depth\": 10,\n",
    "    \"vocab_size\": 256,\n",
    "    \"adaptive_gamma\": \"none\",\n",
    "    \"gamma\": 1/256,\n",
    "    \"lower_bound\": 1e-5,\n",
    "    \"temp\": 1,\n",
    "    \"ensemble_type\": \"depth\",\n",
    "    \"lb_or_temp\": \"lb_first\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_lz = LZModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rust_lz = LZ78SPA(alphabet_size=256, gamma=1/256, compute_training_loss=False)\n",
    "rust_lz.set_inference_config(\n",
    "    lb=1e-5,\n",
    "    temp=1,\n",
    "    lb_or_temp_first=\"lb_first\",\n",
    "    ensemble_type=\"depth\",\n",
    "    ensemble_n=6,\n",
    "    adaptive_gamma=\"disabled\",\n",
    "    backshift_parsing=True,\n",
    "    backshift_ctx_len=10,\n",
    "    backshift_break_at_phrase=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  28602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building LZ tree:   0%|          | 0/28602 [00:00<?, ?it/s]2025-03-12 11:24:00.425640: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:376] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n",
      "Building LZ tree:   0%|          | 99/28602 [00:05<25:12, 18.84it/s] \n"
     ]
    }
   ],
   "source": [
    "N_TRAIN = 100\n",
    "\n",
    "stdout.flush()\n",
    "train_dataloader = PG19DataLoader(\"train\")\n",
    "rust_lz.reset_state()\n",
    "for trn_iter, batch in enumerate(tqdm(train_dataloader, desc=\"Building LZ tree\"), start=1):\n",
    "    # build LZ model only 1 epoch\n",
    "    stdout.flush()\n",
    "    rust_lz.train_on_block(Sequence(batch, alphabet_size=256))\n",
    "    rust_lz.reset_state()\n",
    "\n",
    "    if trn_iter >= N_TRAIN:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  28602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building LZ tree:   0%|          | 99/28602 [00:17<1:25:30,  5.56it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = PG19DataLoader(\"train\")\n",
    "for trn_iter, batch in enumerate(tqdm(train_dataloader, desc=\"Building LZ tree\"), start=1):\n",
    "    # build LZ model only 1 epoch\n",
    "    py_lz.build_tree(batch)\n",
    "\n",
    "    if trn_iter >= N_TRAIN:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation :  50\n"
     ]
    }
   ],
   "source": [
    "val_dataloader = PG19DataLoader(\"validation\")\n",
    "test_seq = next(iter(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seqs = []\n",
    "for i in range(0, len(test_seq)-1023, 512):\n",
    "    test_seqs.append(test_seq[i:i+1024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.09570746 2.02709416 1.92888051 2.24193296 1.94838384 2.246818\n",
      " 2.5534734  1.92000791 2.23535322 2.14238168 2.10381214 2.09425761\n",
      " 2.42312993 2.09602661 2.1823594  2.19796509 2.17546561 2.59972646\n",
      " 2.01459331 2.44875539 3.13992654 2.87137981 2.89687572 2.69475711\n",
      " 2.49312545 3.2878529  2.67884094 2.74689998 2.51736797 2.47719455\n",
      " 2.66557975 3.1036876  2.91649416 3.15200403 2.82862683 2.15703869\n",
      " 2.10913151 2.3850443  2.45824447 2.33437695 2.05443431 2.60664526\n",
      " 2.43794071 2.54737539 2.57753351 2.457468   2.5339743  2.526699\n",
      " 2.66021902 2.88097546 2.73773511 3.11597866 2.21688838 2.4715863\n",
      " 2.27117645 2.00110983 2.19616657 3.0135945  2.66753531 2.50578933\n",
      " 2.40214986 2.89978746 2.53483265 2.66448608 2.65264533 2.62424865\n",
      " 2.7677693  2.75328829 2.34219973 2.34907167 2.59487538 2.5899051\n",
      " 2.4779284  2.40448731 2.81881764 2.82428384 2.52666009 2.46482305\n",
      " 2.47966515 2.31419246 2.15768252 2.53992891 2.59133082 2.41682575\n",
      " 2.78699062 2.43098817 2.2893838  2.27222993 2.3029444  2.77299561\n",
      " 2.97428604 2.80158954 2.86474583 2.6749522  2.59187558 2.45653642\n",
      " 2.16297019 2.08756144 2.42443184 2.68569709 2.55495035 2.52119347\n",
      " 2.4057024  2.83153599 2.56902098 2.37644584 2.5676599  2.36358863\n",
      " 2.75875011 2.49469471 2.75711453 2.15119154 2.62850253 2.4816975\n",
      " 2.72582747 2.73772426 2.47639296 2.43010788 2.07086369 2.71186576\n",
      " 2.7252307  2.57994096 2.13210203 2.92341013 2.35370064 2.048161\n",
      " 2.34097482 2.09704751 2.10926861 3.01142302 2.620014   2.58785429\n",
      " 2.45639214 2.47873495 2.49380244 2.3399683  2.61196532 2.51691852\n",
      " 2.22191182 2.67050442 2.66395419 2.35944119 2.66341454 2.75849135\n",
      " 2.91937135 2.40348347 2.31567069 2.80626905 2.46696712 2.49350139\n",
      " 2.30201243 2.25419397 2.77550868 2.5278964  2.6289177  2.37381135\n",
      " 2.73637544 3.19337288 3.22258738 3.00667277 2.63057259 2.88587935\n",
      " 2.50096261 2.84573809 2.40673365 2.52071591 2.35375015 2.33526028\n",
      " 2.0222817  2.01471275 2.03771995 2.24977343 2.14162905 2.58565131\n",
      " 2.23620425 2.76155602 2.57131305 2.73971728 2.7039767  2.81671072\n",
      " 2.6018584 ]\n"
     ]
    }
   ],
   "source": [
    "stdout.flush()\n",
    "rust_lz.reset_state()\n",
    "\n",
    "inputs = [Sequence(seq[512:],alphabet_size=256) for seq in test_seqs]\n",
    "ctxs = [Sequence(seq[:512],alphabet_size=256) for seq in test_seqs]\n",
    "\n",
    "rust_lz_losses = np.array(rust_lz.compute_test_loss_parallel(\n",
    "    inputs, ctxs, num_threads=32\n",
    ")) / 512\n",
    "print(rust_lz_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_lz_losses = []\n",
    "for seq in test_seqs:\n",
    "    depths, btb, _ = py_lz.get_depth_and_perplexity(seq)\n",
    "    py_lz_losses.append(float(np.mean(btb)))\n",
    "print(py_lz_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(btb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lz_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
