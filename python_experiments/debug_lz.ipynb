{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 15:00:51.181430: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-16 15:00:51.197223: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742162451.216409 1807568 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742162451.222366 1807568 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-16 15:00:51.242493: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from lz78 import Sequence, LZ78SPA\n",
    "from lz_python.lz import LZModel\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from sys import stdout\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PG19DataLoader:\n",
    "    def __init__(self, data_type: str, start_index: int = 0, batch_size: int = 1, normalize: str = 'none'):\n",
    "        self.data = tfds.load('pg19', split=data_type, shuffle_files=False)\n",
    "        self.dataset = (self.data\n",
    "                        .skip(start_index)\n",
    "                        .batch(batch_size)\n",
    "                        .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "        print(data_type, \": \", len(self.dataset))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.dataset:\n",
    "            text_bytes = np.frombuffer(batch['book_text'].numpy()[0], dtype=np.uint8)\n",
    "            text_bytes = text_bytes.tolist()\n",
    "            yield text_bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigObject:\n",
    "    def __init__(self, config_dict):\n",
    "        self.__dict__.update(config_dict)\n",
    "\n",
    "config = ConfigObject({\n",
    "    \"top_k\": 256,\n",
    "    \"method\": \"Depth-Guided\", # ensemble\n",
    "    \"ensemble_max_num\": 6,\n",
    "    \"min_depth\": 10,\n",
    "    \"vocab_size\": 256,\n",
    "    \"adaptive_gamma\": \"none\",\n",
    "    \"gamma\": 1/256,\n",
    "    \"lower_bound\": 1e-5,\n",
    "    \"temp\": 1,\n",
    "    \"ensemble_type\": \"depth\",\n",
    "    \"lb_or_temp\": \"lb_first\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LZModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m py_lz \u001b[38;5;241m=\u001b[39m \u001b[43mLZModel\u001b[49m(config)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LZModel' is not defined"
     ]
    }
   ],
   "source": [
    "py_lz = LZModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rust_lz = LZ78SPA(alphabet_size=256, gamma=1/256, compute_training_loss=False)\n",
    "rust_lz.set_inference_config(\n",
    "    lb=1e-5,\n",
    "    temp=1,\n",
    "    lb_or_temp_first=\"lb_first\",\n",
    "    ensemble_type=\"depth\",\n",
    "    ensemble_n=6,\n",
    "    adaptive_gamma=\"disabled\",\n",
    "    backshift_parsing=True,\n",
    "    backshift_ctx_len=10,\n",
    "    backshift_break_at_phrase=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  28602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building LZ tree:   0%|          | 0/28602 [00:00<?, ?it/s]2025-03-16 15:00:54.191168: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:376] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n",
      "Building LZ tree:   0%|          | 83/28602 [00:04<23:34, 20.16it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m trn_iter, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(train_dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuilding LZ tree\u001b[39m\u001b[38;5;124m\"\u001b[39m), start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# build LZ model only 1 epoch\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     stdout\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m----> 9\u001b[0m     rust_lz\u001b[38;5;241m.\u001b[39mtrain_on_block(Sequence(batch, alphabet_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m))\n\u001b[1;32m     10\u001b[0m     rust_lz\u001b[38;5;241m.\u001b[39mreset_state()\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trn_iter \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m N_TRAIN:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_TRAIN = 300\n",
    "\n",
    "stdout.flush()\n",
    "train_dataloader = PG19DataLoader(\"train\")\n",
    "rust_lz.reset_state()\n",
    "for trn_iter, batch in enumerate(tqdm(train_dataloader, desc=\"Building LZ tree\"), start=1):\n",
    "    # build LZ model only 1 epoch\n",
    "    stdout.flush()\n",
    "    rust_lz.train_on_block(Sequence(batch, alphabet_size=256))\n",
    "    rust_lz.reset_state()\n",
    "\n",
    "    if trn_iter >= N_TRAIN:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  28602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building LZ tree:   1%|          | 299/28602 [00:59<1:33:53,  5.02it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = PG19DataLoader(\"train\")\n",
    "for trn_iter, batch in enumerate(tqdm(train_dataloader, desc=\"Building LZ tree\"), start=1):\n",
    "    # build LZ model only 1 epoch\n",
    "    py_lz.build_tree(batch)\n",
    "\n",
    "    if trn_iter >= N_TRAIN:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = PG19DataLoader(\"validation\")\n",
    "test_seq = next(iter(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seqs = []\n",
    "for i in range(0, len(test_seq)-1023, 512):\n",
    "    test_seqs.append(test_seq[i:i+1024])\n",
    "\n",
    "test_seqs = test_seqs[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout.flush()\n",
    "\n",
    "inputs = [Sequence(seq[512:],alphabet_size=256) for seq in test_seqs]\n",
    "ctxs = [Sequence(seq[:512],alphabet_size=256) for seq in test_seqs]\n",
    "\n",
    "res = rust_lz.compute_test_loss_parallel(\n",
    "    inputs, ctxs, num_threads=32, output_prob_dists=False, output_per_symbol_losses=False\n",
    ")\n",
    "print(np.array([x[\"avg_log_loss\"] for x in res]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_lz_losses = []\n",
    "for seq in test_seqs:\n",
    "    depths, btb, _ = py_lz.get_depth_and_perplexity(seq)\n",
    "    py_lz_losses.append(float(np.mean(btb)))\n",
    "print(np.array(py_lz_losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Full Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss = 0\n",
    "n_seqs = 0\n",
    "val_dataloader = PG19DataLoader(\"validation\")\n",
    "for seq in tqdm(val_dataloader):\n",
    "    stdout.flush()\n",
    "    test_seqs = []\n",
    "    for i in range(0, len(seq)-1023, 512):\n",
    "        test_seqs.append(seq[i:i+1024])\n",
    "\n",
    "    rust_lz.reset_state()\n",
    "\n",
    "    inputs = [Sequence(seq[512:],alphabet_size=256) for seq in test_seqs]\n",
    "    ctxs = [Sequence(seq[:512],alphabet_size=256) for seq in test_seqs]\n",
    "\n",
    "    res = rust_lz.compute_test_loss_parallel(\n",
    "        inputs, ctxs, num_threads=32, output_prob_dists=False, output_per_symbol_losses=False\n",
    "    )\n",
    "\n",
    "    losses = np.array([x[0] for x in res]) / 512\n",
    "    log_loss += np.sum(losses)\n",
    "    n_seqs += len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Val PPL: {2**float(log_loss / n_seqs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return Patch Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = PG19DataLoader(\"validation\")\n",
    "test_seq = next(iter(val_dataloader))[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = rust_lz.compute_test_loss( # also works for the parallel version!\n",
    "    Sequence(test_seq, alphabet_size=256), output_prob_dists=False, output_per_symbol_losses=True, output_patch_info=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This looks reasonable; should maybe debug more\n",
    "for info in res['patch_info']:\n",
    "    print(f\"{info[0]} through {info[1] - 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.stem(np.array(res['log_losses']))\n",
    "plt.title(\"Log Loss per Symbol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lz_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
